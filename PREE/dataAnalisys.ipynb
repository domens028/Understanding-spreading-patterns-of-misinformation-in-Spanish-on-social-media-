{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "from dash import Dash, html, dcc\n",
    "import plotly.express as px\n",
    "from urllib.parse import urlparse\n",
    "from langdetect import detect\n",
    "from datetime import date\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group(name,date,data):\n",
    "    table = data.groupby([name])['id'].count()\n",
    "    df = table.to_frame().reset_index()\n",
    "    df.rename(columns = {'id':'ocurrences'}, inplace = True)\n",
    "    if(date != 'today'):\n",
    "        others = df[df.ocurrences < 10]\n",
    "        df=df.drop(others.index)\n",
    "        df=df.append({name:'others','ocurrences':others.count().ocurrences},ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def groupBy(name,date,data):\n",
    "    df = group(name,date,data)\n",
    "    df = df.sort_values('ocurrences', ascending=True)\n",
    "    df.to_csv('tables/'+name+date+'ByOcurrencesPlot.csv',index=False) \n",
    "\n",
    "def languagueGroupBy(name,date,data,languague):\n",
    "    df = group(name,date,data)\n",
    "    df = df.sort_values('ocurrences', ascending=True)\n",
    "    df.to_csv('tables/'+languague+'/'+name+date+'ByOcurrencesPlot.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Domain Analisis \n",
    "#Dominios compartidos por canales \n",
    "def ChannelPerPost(data):#Número de Canales que se comparten por post\n",
    "    table = data.groupby(['channel'])['id'].count()\n",
    "    df= table.to_frame().reset_index()\n",
    "    return df\n",
    "\n",
    "def DomainsPerPost(data):#Número de dominios compartidos por post\n",
    "    table = data.groupby(['url'])['id'].count()\n",
    "    df= table.to_frame().reset_index()\n",
    "    return df\n",
    "\n",
    "def PostPerTwitter(data):#Número de veces que un post se comparte en telegram y acaba en twitter\n",
    "    table = data.groupby(['id','date'])['TwitterId'].count()\n",
    "    df = table.to_frame().reset_index()\n",
    "    return df\n",
    "\n",
    "def DomainsPerTwitter(data):#Número de veces que un dominio se comparte en telegram y acaba en twitter\n",
    "    table = data.groupby(['url','date'])['TwitterId'].count()\n",
    "    df = table.to_frame().reset_index()\n",
    "    return df\n",
    "\n",
    "\n",
    "def RetweetPerDomain(data):#Numero de retweet en función del dominio\n",
    "    table = data.groupby(['url'])['retweet'].sum()\n",
    "    df = table.to_frame().reset_index()\n",
    "    df = df.sort_values('retweet', ascending=True)\n",
    "    df.to_csv('tables/RetweetPerDomain.csv',index=False) \n",
    "    return df\n",
    "\n",
    "def LikesPerDomain(data):#Numero de me gustas en función del dominio\n",
    "    table = data.groupby(['url'])['favorites'].sum()\n",
    "    df = table.to_frame().reset_index()\n",
    "    df = df.sort_values('favorites', ascending=True)\n",
    "    df.to_csv('tables/LikePerDomian.csv',index=False) \n",
    "    return df\n",
    "\n",
    "def RetweetPerChannel(data):#Numero de retweet en función del dominio\n",
    "    table = data.groupby(['channel'])['retweet'].sum()\n",
    "    df = table.to_frame().reset_index()\n",
    "    df = df.sort_values('retweet', ascending=True)\n",
    "    df.to_csv('tables/RetweetPerChannel.csv',index=False) \n",
    "    return df\n",
    "\n",
    "def LikesPerChannel(data):#Numero de me gustas en función del dominio\n",
    "    table = data.groupby(['channel'])['favorites'].sum()\n",
    "    df = table.to_frame().reset_index()\n",
    "    df = df.sort_values('favorites', ascending=True)\n",
    "    df.to_csv('tables/LikePerChannel.csv',index=False) \n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0       18639\n",
      "channel          18639\n",
      "id               18639\n",
      "twitter          18639\n",
      "title            18639\n",
      "url              18639\n",
      "date             18639\n",
      "text             11095\n",
      "languague        18639\n",
      "TwitterId         1636\n",
      "TwitterText       1636\n",
      "favorites         1636\n",
      "name              1383\n",
      "quoted_tweets     1636\n",
      "retweet           1636\n",
      "TwitterDate       1636\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('dataset.csv')\n",
    "print(data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def hostNameTranformation(data):\n",
    "     for index,row in data.iterrows():\n",
    "        host = row['url']\n",
    "        if(not (host.startswith('www.'))):\n",
    "                data['url'].loc[index] = 'www.' + host\n",
    "                            \n",
    "     return data\n",
    " \n",
    "data = hostNameTranformation(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0       16242\n",
      "channel          16242\n",
      "id               16242\n",
      "twitter          16242\n",
      "title            16242\n",
      "url              16242\n",
      "date             16242\n",
      "text             16242\n",
      "languague        16242\n",
      "TwitterId         1455\n",
      "TwitterText       1455\n",
      "favorites         1455\n",
      "name              1202\n",
      "quoted_tweets     1455\n",
      "retweet           1455\n",
      "TwitterDate       1282\n",
      "date_ms          16242\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Limpiamos la base de datos, tras observar que hay campos que tienen el title=='NEWS? y el text =='NULL'\n",
    "data= data.drop(data[(data['twitter'] =='no_data') & (data['title'] =='NEWS') & (data['text'].isnull())].index)\n",
    "pr = data[~data['text'].str.contains('JavaScript', na = False)]\n",
    "data= data.drop(data[data['text'].str.contains('JavaScript', na = False)].index)\n",
    "data = data.replace({'TwitterDate': {'no_data': 0}})\n",
    "#Le quitamos los segundos a las fechas\n",
    "data['date_ms'] = data['date']\n",
    "data['date'] = data['date'].str.slice(stop=10)\n",
    "data['TwitterDate'] = data['TwitterDate'].str.slice(stop=10)\n",
    "#Los convertimos en date con el formato  yyyy-mm-dd\n",
    "data['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d')\n",
    "data['TwitterDate'] = pd.to_datetime(data['TwitterDate'], format='%Y-%m-%d')\n",
    "#Completamos con los campos text vacios \n",
    "data = data.fillna({'text': data.TwitterText})#completamos con twitter siempre que se pueda\n",
    "data = data.fillna({'text': data.title})#completamos con title cuando no se pueda con twitter\n",
    "#Corregimos el lenguaje \n",
    "languague = []\n",
    "for index,row in data.iterrows():\n",
    "    try:\n",
    "        languague.append(detect(row['text']))\n",
    "    except:\n",
    "        languague.append(0)\n",
    "        \n",
    "data['languague'] = languague       \n",
    "print(data.count())\n",
    "data.to_csv('data_bertopic3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = data.groupby(['url'])['retweet'].count()\n",
    "df = table.to_frame().reset_index()\n",
    "df = df.sort_values('retweet', ascending=True)\n",
    "df.to_csv('media.csv',index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date TwitterDate     antes\n",
      "1     2022-11-23  2022-11-21   Twitter\n",
      "2     2022-11-23  2022-11-21   Twitter\n",
      "3     2022-11-23  2022-11-21   Twitter\n",
      "4     2022-11-23  2022-11-22   Twitter\n",
      "5     2022-11-23  2022-11-22   Twitter\n",
      "...          ...         ...       ...\n",
      "12844 2022-12-14  2022-12-17  Telegram\n",
      "12848 2022-12-19  2022-12-19   Twitter\n",
      "12849 2022-12-19  2022-12-19   Twitter\n",
      "12850 2022-12-19  2022-12-19   Twitter\n",
      "12851 2022-12-19  2022-12-19   Twitter\n",
      "\n",
      "[1455 rows x 3 columns]\n",
      "Twitter     1129\n",
      "Telegram     326\n",
      "Name: antes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Analisis de direccionabilidad \n",
    "#cogemos solo los datos con tweets \n",
    "df = data.loc[(data['TwitterId'] > 0)]\n",
    "df = df.assign(antes = np.where((df.date >= df.TwitterDate),'Twitter','Telegram'))\n",
    "print(df.loc[:, ['date', 'TwitterDate','antes']])\n",
    "print(df.antes.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Telegram to Twitter\n",
    "df2 = df.loc[(df['antes'] == 'Telegram')]\n",
    "dmxps = DomainsPerPost(df2)\n",
    "chxps = ChannelPerPost(df2)\n",
    "dmxps = dmxps.sort_values('id', ascending=True)\n",
    "chxps = chxps.sort_values('id', ascending=True)\n",
    "dmxps.to_csv('tables/TelegramToTwitter.csv',index=False) \n",
    "chxps.to_csv('tables/ChannelsTelegramToTwitter.csv',index=False) \n",
    "#Twitter to Telegram\n",
    "df2 = df.loc[(df['antes'] == 'Twitter')]\n",
    "dmxps = DomainsPerPost(df2)\n",
    "chxps = ChannelPerPost(df2)\n",
    "dmxps = dmxps.sort_values('id', ascending=True)\n",
    "chxps = chxps.sort_values('id', ascending=True)\n",
    "dmxps.to_csv('tables/TwitterToTelegram.csv',index=False) \n",
    "chxps.to_csv('tables/ChannelsTwitterToTelegram.csv',index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POST \n",
    "chxps = ChannelPerPost(data) \n",
    "dmxps = DomainsPerPost(data)\n",
    "#DOMINIOS \n",
    "psxtw = PostPerTwitter(data)\n",
    "dmxtw = DomainsPerTwitter(data)\n",
    "rtxdm = RetweetPerDomain(data)\n",
    "lkxdm = LikesPerDomain(data)\n",
    "#CHANNELS \n",
    "rtxch = RetweetPerChannel(data)\n",
    "lkxch = LikesPerChannel(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date of analisis \n",
    "import datetime\n",
    "fecha = datetime.datetime(2023, 2, 8)\n",
    "\n",
    "today = data.loc[(data['date'] == fecha)]\n",
    "\n",
    "groupBy('url','today',today)\n",
    "groupBy('channel','today',today)\n",
    "groupBy('languague','today',today)\n",
    "\n",
    "#lastWeek\n",
    "filterDate = fecha - timedelta(days=7)\n",
    "lastweek = data.loc[(data['date'] >= filterDate)\n",
    "                     & (data['date'] < fecha)]\n",
    "groupBy('url','lastweek',lastweek)\n",
    "groupBy('channel','lastweek',lastweek)\n",
    "groupBy('languague','lastweek',lastweek)\n",
    "\n",
    "#lastMonth\n",
    "filterDate = fecha - timedelta(days=30)\n",
    "lastmonth = data.loc[(data['date'] >= filterDate)\n",
    "                     & (data['date'] < fecha)]\n",
    "\n",
    "groupBy('url','lastmonth',lastmonth)\n",
    "groupBy('channel','lastmonth',lastmonth)\n",
    "groupBy('languague','lastmonth',lastmonth)\n",
    "#allDataSet\n",
    "groupBy('url','all',data)\n",
    "groupBy('channel','all',data)\n",
    "groupBy('languague','all',data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     url   id\n",
      "33     www.elpais.com.uy    1\n",
      "28          www.eitb.eus    1\n",
      "29   www.eldiasegovia.es    1\n",
      "102   www.sevilla.abc.es    1\n",
      "34   www.elperiodico.com    1\n",
      "..                   ...  ...\n",
      "31        www.elmundo.es   76\n",
      "54         www.gaceta.es   76\n",
      "83        www.nypost.com   84\n",
      "101       www.rumble.com  104\n",
      "45      www.facebook.com  159\n",
      "\n",
      "[129 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dmxps = DomainsPerPost(df)\n",
    "dmxps = dmxps.sort_values('id', ascending=True)\n",
    "print(dmxps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segundo analisis descriptivo por lenguaje \n",
    "#Date of analisis \n",
    "import os \n",
    "lan = ['es','en']\n",
    "path = os.getcwd() \n",
    "\n",
    "for x in lan:\n",
    "      #We create the folders for the tables\n",
    "      try:\n",
    "            os.mkdir(path+'/tables/'+str(x))\n",
    "      except OSError as error:\n",
    "            error\n",
    "            \n",
    "      #We filter by  languague \n",
    "      df = data.loc[(data['languague'] == x)]\n",
    "      #We filter by the date\n",
    "\n",
    "      today = df.loc[(df['date'] == fecha)]\n",
    "      languagueGroupBy('url','today',today,str(x))\n",
    "      languagueGroupBy('channel','today',today,str(x))\n",
    "      #lastWeek\n",
    "      filterDate = fecha - timedelta(days=7)\n",
    "      lastweek = df.loc[(df['date'] >= filterDate)\n",
    "                        & (df['date'] < fecha)]\n",
    "      languagueGroupBy('url','lastweek',lastweek,str(x))\n",
    "      languagueGroupBy('channel','lastweek',lastweek,str(x))\n",
    "      \n",
    "      #lastMonth\n",
    "      filterDate = fecha - timedelta(days=30)\n",
    "      lastmonth = df.loc[(df['date'] >= filterDate)\n",
    "                        & (df['date'] < fecha)]\n",
    "\n",
    "      languagueGroupBy('url','lastmonth',lastmonth,str(x))\n",
    "      languagueGroupBy('channel','lastmonth',lastmonth,str(x))\n",
    "\n",
    "      #allDataSet\n",
    "      languagueGroupBy('url','all',df,str(x))\n",
    "      languagueGroupBy('channel','all',df,str(x))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
